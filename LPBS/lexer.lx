@module "lexer"

@use "string" as string

pub const TokenType -> enum {
  TOK_NUMBER,
  TOK_IDENT,
  TOK_STRING,
  TOK_SYMBOL,
  TOK_WHITESPACE,

  TOK_EQUALS,
  TOK_SEMICOLON,
  TOK_LPAREN,
  TOK_RPAREN,
  TOK_LBRACE,
  TOK_RBRACE,
  TOK_UNKNOWN,
};

const K_Symbol_Map -> struct { value: *char, type: int };
const D_Symbol_Map -> struct { value: *char, type: int };
const S_Symbol_Map -> struct { value:  char, type: int };

pub const Token -> struct {
  list: *Token,
  size: int,
  capacity: int,
  value: *char,
  type: int,
  line: int,
  col: int,
};

const s_symbol: [S_Symbol_Map; 6] = [
 S_Symbol_Map {value: '=', type: TokenType::TOK_EQUALS}, S_Symbol_Map {value: ';', type: TokenType::TOK_SEMICOLON}, 
 S_Symbol_Map {value: '(', type: TokenType::TOK_LPAREN}, S_Symbol_Map {value: ')', type: TokenType::TOK_RPAREN}, 
 S_Symbol_Map {value: '{', type: TokenType::TOK_LBRACE}, S_Symbol_Map {value: '}', type: TokenType::TOK_RBRACE}
];

#takes_ownership
pub const free_tokens -> fn (tks: *Token) void {
  loop [i: int = 0](i < tks.size) : (++i) {
    if (tks.list[i].value != cast<*char>(0)) {
      free(tks.list[i].value);
    }
  }
  free(tks.list);
  free(tks);
}

const make_token -> fn (type: int, value: *char, line: int, col: int) Token {
  let tk: Token;
  tk.type = type;
  tk.value = value;
  tk.line = line;
  tk.col = col;
  return tk;
}

const is_whitespace -> fn (ch: char) bool {
  return (ch == ' ' || ch == '\t' || ch == '\n' || ch == '\r');
}

#returns_ownership
pub const scan -> fn (path: *char) *Token {
  let src_len: int = string::strlen(path);
  let tks: *Token = cast<*Token>(alloc(sizeof<Token>));
  
  tks.capacity = src_len * 2;  // Increase capacity
  tks.list = cast<*Token>(alloc(tks.capacity * sizeof<Token>));
  tks.size = 0; 
  tks.line = 1;
  tks.col  = 1;

  let i: int = 0;
  loop (i < src_len) {
    let ch: char = path[i];
    
    // Skip whitespace but count lines/cols
    if (is_whitespace(ch)) {
      if (ch == '\n') {
        tks.line = tks.line + 1;
        tks.col = 1;
      } else {
        tks.col = tks.col + 1;
      }
      i = i + 1;
      continue;
    }
    
    // Handle identifiers and keywords
    if (string::is_alpha(ch)) {
      let start_pos: int = i;
      let start_col: int = tks.col;
      
      // Scan to end of identifier
      loop ((i < src_len) && string::is_alnum(path[i])) {
        i = i + 1;
        tks.col = tks.col + 1;
      }
      
      let length: int = i - start_pos;
      let word: *char = cast<*char>(alloc(length + 1));
      
      // Copy the identifier
      let k: int = 0;
      loop (k < length) {
        word[k] = path[start_pos + k];
        k = k + 1;
      }
      word[length] = '\0';
      
      // Store token
      tks.list[tks.size] = make_token(TokenType::TOK_IDENT, word, tks.line, start_col);
      tks.size = tks.size + 1;
      continue;
    }
    
    // Handle numbers
    if (string::is_digit(ch)) {
      let start_pos: int = i;
      let start_col: int = tks.col;
      
      loop ((i < src_len) && string::is_digit(path[i])) {
        i = i + 1;
        tks.col = tks.col + 1;
      }
      
      let length: int = i - start_pos;
      let num: *char = cast<*char>(alloc(length + 1));
      
      let k: int = 0;
      loop (k < length) {
        num[k] = path[start_pos + k];
        k = k + 1;
      }
      num[length] = '\0';
      
      tks.list[tks.size] = make_token(TokenType::TOK_NUMBER, num, tks.line, start_col);
      tks.size = tks.size + 1;
      continue;
    }
    
    // Handle string literals
    if (ch == '"') {
      let start_col: int = tks.col;
      i = i + 1;
      tks.col = tks.col + 1;
      let start_pos: int = i;
      
      loop ((i < src_len) && (path[i] != '"')) {
        i = i + 1;
        tks.col = tks.col + 1;
      }
      
      let length: int = i - start_pos;
      let str_val: *char = cast<*char>(alloc(length + 1));
      
      let k: int = 0;
      loop (k < length) {
        str_val[k] = path[start_pos + k];
        k = k + 1;
      }
      str_val[length] = '\0';
      
      tks.list[tks.size] = make_token(TokenType::TOK_STRING, str_val, tks.line, start_col);
      tks.size = tks.size + 1;
      
      i = i + 1;  // Skip closing quote
      tks.col = tks.col + 1;
      continue;
    }
    
    let matched: int = 0;
    loop [k: int = 0](k < 6) : (++k) {
      if (ch == s_symbol[k].value) {
        let start_col: int = tks.col;
        tks.list[tks.size] = make_token(s_symbol[k].type,  string::from_char(ch), tks.line, start_col);
        tks.size = tks.size + 1;
        tks.col = tks.col + 1;
        i = i + 1;
        matched = 1;
        break;
      }
    }

    if (matched != 1) { 
      // Handle single character symbols
      let start_col: int = tks.col;
      tks.list[tks.size] = make_token(TokenType::TOK_SYMBOL,  string::from_char(ch), tks.line, start_col);
      tks.size = tks.size + 1;
      tks.col = tks.col + 1;
      i = i + 1;
    }
  }

  return tks;
}


